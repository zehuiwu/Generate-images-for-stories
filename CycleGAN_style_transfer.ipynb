{"cells":[{"cell_type":"markdown","source":["\n","## **Acknowledgement**\n"," **This is a revised notebook from [Improving CycleGAN - Monet paintings](https://www.kaggle.com/code/dimitreoliveira/improving-cyclegan-monet-paintings)**"],"metadata":{"id":"4CXY7kaNz7dJ"},"id":"4CXY7kaNz7dJ"},{"cell_type":"markdown","id":"stock-throw","metadata":{"id":"stock-throw"},"source":["\n","<p>\n","<h1><center> Style Transfer</center></h1>\n","<h2><center> CycleGAN - Hayao Miyazaki and Makoto Shinkai Styles  </center></h2>\n","\n","### This notebook was created to try several experiments to the original CycleGan (or at least a vey close one) implementation, and see what works or not for this specific task.\n","\n","#### Experiments (Starting from the original paper architecture):\n","- Transformer with residual blocks [++]\n","- Residual connections between Generator and Discriminator [++]\n","- Not using `InstanceNorm` at the first layer of both generator and discriminator [++]\n","- Better `InstanceNorm` layer initialization [++]\n","- Training a lot longer [++]\n","- Better `Conv` layer initialization [+]\n","- Residual connection with `Concatenate` instead of `Add` [+]\n","- Data augmentations (flips, rotations, and crops) [+]\n","- Discriminator with label smoothing [+]\n","- Using [external data](https://www.kaggle.com/dimitreoliveira/tfrecords-monet-paintings-256x256) (1193 files) [+-]\n","- Train on crops [+-]\n","- Decoder with resize-convolution [+-]\n","- 9 transformer blocks [+-]\n","- Patch discriminator [+-]\n","- Lager batch size [+-]"]},{"cell_type":"code","execution_count":1,"id":"hogYYFiHzW8d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24207,"status":"ok","timestamp":1713704551887,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"hogYYFiHzW8d","outputId":"2d5749c9-b29d-4127-c272-db451b702b33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/CycleGAN\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/CycleGAN"]},{"cell_type":"code","execution_count":2,"id":"GMsRrfVs1sD_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6202,"status":"ok","timestamp":1713704558044,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"GMsRrfVs1sD_","outputId":"20160ded-4807-45c6-b88f-b649a9983ad9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/611.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow_addons\n","Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"]}],"source":["!pip install tensorflow_addons"]},{"cell_type":"markdown","id":"sapphire-scheduling","metadata":{"id":"sapphire-scheduling"},"source":["## Dependencies"]},{"cell_type":"code","execution_count":3,"id":"logical-blogger","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4817,"status":"ok","timestamp":1713704562810,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"logical-blogger","outputId":"ee4b62b4-2898-495f-d8b2-193e79399d53"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import os, random, json, PIL, shutil, re, imageio, glob\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from PIL import ImageDraw\n","import matplotlib.pyplot as plt\n","# from kaggle_datasets import KaggleDatasets\n","import tensorflow as tf\n","import tensorflow.keras.layers as L\n","import tensorflow.keras.backend as K\n","import tensorflow_addons as tfa\n","from tensorflow.keras import Model, losses, optimizers\n","from tensorflow.keras.callbacks import Callback\n","\n","\n","def seed_everything(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","SEED = 0\n","seed_everything(SEED)"]},{"cell_type":"markdown","id":"southwest-graphic","metadata":{"id":"southwest-graphic"},"source":["## TPU configuration"]},{"cell_type":"code","execution_count":4,"id":"mobile-tragedy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90,"status":"ok","timestamp":1713704563270,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"mobile-tragedy","outputId":"3f1b1fb0-a6bb-4b9d-c2d8-ace1e69b591e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on GPU: GPU /physical_device:GPU:0\n","GPU is available\n"]}],"source":["try:\n","    gpus = tf.config.list_physical_devices('GPU')\n","    if not gpus:\n","        raise RuntimeError('GPU not found')\n","\n","    # Assuming there is only one GPU available.\n","    gpu = gpus[0]\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","    print(f'Running on GPU: {gpu.device_type} {gpu.name}')\n","except RuntimeError as e:\n","    print(e)\n","    gpu = None\n","\n","if gpu:\n","    print(\"GPU is available\")\n","else:\n","    print(\"GPU is not available\")"]},{"cell_type":"markdown","id":"patient-peripheral","metadata":{"id":"patient-peripheral"},"source":["# Model parameters"]},{"cell_type":"code","execution_count":5,"id":"available-mailing","metadata":{"id":"available-mailing","executionInfo":{"status":"ok","timestamp":1713704563271,"user_tz":240,"elapsed":79,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["HEIGHT = 256\n","WIDTH = 256\n","HEIGHT_RESIZE = 128\n","WIDTH_RESIZE = 128\n","CHANNELS = 3\n","BATCH_SIZE = 16\n","EPOCHS = 30\n","TRANSFORMER_BLOCKS = 6\n","GENERATOR_LR = 2e-4\n","DISCRIMINATOR_LR = 2e-4\n","AUTO = tf.data.experimental.AUTOTUNE"]},{"cell_type":"markdown","id":"realistic-norwegian","metadata":{"id":"realistic-norwegian"},"source":["# Load data"]},{"cell_type":"code","execution_count":6,"id":"ec30d5b1","metadata":{"id":"ec30d5b1","executionInfo":{"status":"ok","timestamp":1713704643578,"user_tz":240,"elapsed":80375,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["from PIL import Image\n","import tensorflow as tf\n","import os\n","import io\n","\n","def _bytes_feature(value):\n","    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def serialize_example(image):\n","    feature = {\n","        'image': _bytes_feature(image),\n","    }\n","    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n","    return example_proto.SerializeToString()\n","\n","def process_image_file(file_path):\n","    img = Image.open(file_path)\n","    # img = img.resize((256, 256))  # Resize images as needed\n","\n","    # Save image to byte buffer as JPEG\n","    img_byte_arr = io.BytesIO()\n","    img.save(img_byte_arr, format='JPEG')  # Ensure your images are saved as JPEG\n","    img_byte_arr = img_byte_arr.getvalue()\n","\n","    return img_byte_arr\n","\n","def create_tfrecord_file(output_filename, image_dir):\n","    with tf.io.TFRecordWriter(output_filename) as writer:\n","        for filename in os.listdir(image_dir):\n","            file_path = os.path.join(image_dir, filename)\n","            if file_path.endswith(\".jpg\") or file_path.endswith(\".png\"):  # Check for image formats\n","                image = process_image_file(file_path)\n","                example = serialize_example(image)\n","                writer.write(example)\n","\n","# Example usage:\n","create_tfrecord_file('shinkai.tfrecord', 'dataset/Shinkai/smooth')\n","# create_tfrecord_file('train_photo.tfrecord', 'dataset/train_photo')\n","# create_tfrecord_file('test_photo.tfrecord', 'dataset/test/custom_test')\n"]},{"cell_type":"code","execution_count":7,"id":"fixed-geneva","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8221,"status":"ok","timestamp":1713704651741,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"fixed-geneva","outputId":"9f7de1a2-5c06-459b-f3c7-c51bd8deeb4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Anime TFRecord files: 1\n","Anime image files: 1650\n","Photo TFRecord files: 1\n","Photo image files: 6656\n"]}],"source":["ANIME_FILENAMES = tf.io.gfile.glob('shinkai.tfrecord')\n","PHOTO_FILENAMES = tf.io.gfile.glob('train_photo.tfrecord')\n","TEST_FILENAMES = tf.io.gfile.glob('test_photo.tfrecord')\n","\n","def count_records_in_tfrecord(file_path):\n","    count = 0\n","    for record in tf.data.TFRecordDataset(file_path):\n","        count += 1\n","    return count\n","\n","n_anime_samples = sum(count_records_in_tfrecord(f) for f in ANIME_FILENAMES)\n","n_photo_samples = sum(count_records_in_tfrecord(f) for f in PHOTO_FILENAMES)\n","\n","print(f'Anime TFRecord files: {len(ANIME_FILENAMES)}')\n","print(f'Anime image files: {n_anime_samples}')\n","print(f'Photo TFRecord files: {len(PHOTO_FILENAMES)}')\n","print(f'Photo image files: {n_photo_samples}')"]},{"cell_type":"markdown","id":"normal-auckland","metadata":{"id":"normal-auckland"},"source":["# Augmentations\n","\n","Data augmentation for GANs should be done very carefully, especially for tasks similar to style transfer, if we apply transformations that can change too much the style of the data (e.g. brightness, contrast, saturation) it can cause the generator to do not efficiently learn the base style, so in this case, we are using only spatial transformations like, flips, rotates and crops."]},{"cell_type":"code","execution_count":8,"id":"negative-malaysia","metadata":{"id":"negative-malaysia","executionInfo":{"status":"ok","timestamp":1713704651743,"user_tz":240,"elapsed":68,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["def data_augment(image):\n","    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","#     p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","\n","\n","#     # Random jitter\n","#     image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","\n","    # 90º rotations\n","    if p_rotate > .8:\n","        image = tf.image.rot90(image, k=3) # rotate 270º\n","    elif p_rotate > .6:\n","        image = tf.image.rot90(image, k=2) # rotate 180º\n","    elif p_rotate > .4:\n","        image = tf.image.rot90(image, k=1) # rotate 90º\n","\n","    # Flips\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","    if p_spatial > .75:\n","        image = tf.image.transpose(image)\n","\n","#     # Crops\n","#     if p_crop > .6: # random crop\n","#         crop_size = tf.random.uniform([], int(HEIGHT*.7), HEIGHT, dtype=tf.int32)\n","#         image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n","#     elif p_crop > .2: # central crop\n","#         if p_crop > .5:\n","#             image = tf.image.central_crop(image, central_fraction=.7)\n","#         elif p_crop > .35:\n","#             image = tf.image.central_crop(image, central_fraction=.8)\n","#         else:\n","#             image = tf.image.central_crop(image, central_fraction=.9)\n","\n","    # Train on crops\n","    # image = tf.image.random_crop(image, size=[HEIGHT_RESIZE, WIDTH_RESIZE, CHANNELS])\n","\n","\n","    return image"]},{"cell_type":"markdown","id":"cultural-weather","metadata":{"id":"cultural-weather"},"source":["## Auxiliar functions"]},{"cell_type":"code","execution_count":9,"id":"political-fireplace","metadata":{"id":"political-fireplace","executionInfo":{"status":"ok","timestamp":1713704651743,"user_tz":240,"elapsed":52,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["def normalize_img(img):\n","    img = tf.cast(img, dtype=tf.float32)\n","    # Map values in the range [-1, 1]\n","    return (img / 127.5) - 1.0\n","\n","def decode_image(image):\n","    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n","    # image = tf.reshape(image, [HEIGHT, WIDTH, CHANNELS])\n","    return image\n","\n","def read_tfrecord(example):\n","    tfrecord_format = {\n","        'image':      tf.io.FixedLenFeature([], tf.string)\n","    }\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example['image'])\n","    return image\n","\n","def load_dataset(filenames):\n","    dataset = tf.data.TFRecordDataset(filenames)\n","    dataset = dataset.map(read_tfrecord)\n","    return dataset\n","\n","def get_dataset(filenames, augment=None, repeat=True, shuffle=True, batch_size=1):\n","    dataset = load_dataset(filenames)\n","\n","    if augment:\n","        dataset = dataset.map(augment)\n","    dataset = dataset.map(normalize_img)\n","    if repeat:\n","        dataset = dataset.repeat()\n","    if shuffle:\n","        dataset = dataset.shuffle(512)\n","\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.cache()\n","    dataset = dataset.prefetch(AUTO)\n","\n","    return dataset\n","\n","def display_samples(ds, n_samples):\n","    ds_iter = iter(ds)\n","    for n_sample in range(n_samples):\n","        example_sample = next(ds_iter)\n","        plt.subplot(121)\n","        plt.imshow(example_sample[0] * 0.5 + 0.5)\n","        plt.axis('off')\n","        plt.show()\n","\n","def display_generated_samples(ds, model, n_samples):\n","    ds_iter = iter(ds)\n","    for n_sample in range(n_samples):\n","        example_sample = next(ds_iter)\n","        generated_sample = model.predict(example_sample)\n","\n","        f = plt.figure(figsize=(12, 12))\n","\n","        plt.subplot(121)\n","        plt.title('Input image')\n","        plt.imshow(example_sample[0] * 0.5 + 0.5)\n","        plt.axis('off')\n","\n","        plt.subplot(122)\n","        plt.title('Generated image')\n","        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n","        plt.axis('off')\n","        plt.show()\n","\n","def evaluate_cycle(ds, generator_a, generator_b, n_samples=1):\n","    fig, axes = plt.subplots(n_samples, 3, figsize=(22, (n_samples*6)))\n","    axes = axes.flatten()\n","\n","    ds_iter = iter(ds)\n","    for n_sample in range(n_samples):\n","        idx = n_sample*3\n","        example_sample = next(ds_iter)\n","        generated_a_sample = generator_a.predict(example_sample)\n","        generated_b_sample = generator_b.predict(generated_a_sample)\n","\n","        axes[idx].set_title('Input image', fontsize=18)\n","        axes[idx].imshow(example_sample[0] * 0.5 + 0.5)\n","        axes[idx].axis('off')\n","\n","        axes[idx+1].set_title('Generated image', fontsize=18)\n","        axes[idx+1].imshow(generated_a_sample[0] * 0.5 + 0.5)\n","        axes[idx+1].axis('off')\n","\n","        axes[idx+2].set_title('Cycled image', fontsize=18)\n","        axes[idx+2].imshow(generated_b_sample[0] * 0.5 + 0.5)\n","        axes[idx+2].axis('off')\n","\n","    plt.show()\n","\n","def create_gif(images_path, gif_path):\n","    images = []\n","    filenames = glob.glob(images_path)\n","    filenames.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n","    for epoch, filename in enumerate(filenames):\n","        img = PIL.ImageDraw.Image.open(filename)\n","        ImageDraw.Draw(img).text((0, 0),  # Coordinates\n","                                 f'Epoch {epoch+1}')\n","        images.append(img)\n","    imageio.mimsave(gif_path, images, fps=2) # Save gif\n","\n","def predict_and_save(input_ds, generator_model, output_path):\n","    i = 1\n","    for img in input_ds:\n","        prediction = generator_model(img, training=False)[0].numpy() # make predition\n","        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)   # re-scale\n","        im = PIL.Image.fromarray(prediction)\n","        im.save(f'{output_path}{str(i)}.jpg')\n","        i += 1"]},{"cell_type":"markdown","id":"greater-shape","metadata":{"id":"greater-shape"},"source":["## Auxiliar functions (model)\n","\n","Here we the building blocks of our models:\n","- Encoder block: Apply convolutional filters while also reducing data resolution and increasing features.\n","- Decoder block: Apply convolutional filters while also increasing data resolution and decreasing features.\n","- Transformer block: Apply convolutional filters to find relevant data patterns and keeps features constant."]},{"cell_type":"code","execution_count":10,"id":"sticky-allah","metadata":{"id":"sticky-allah","executionInfo":{"status":"ok","timestamp":1713704651743,"user_tz":240,"elapsed":45,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["conv_initializer = tf.random_normal_initializer(mean=0.0, stddev=0.02)\n","gamma_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n","\n","def encoder_block(input_layer, filters, size=3, strides=2, apply_instancenorm=True, activation=L.ReLU(), name='block_x'):\n","    block = L.Conv2D(filters, size,\n","                     strides=strides,\n","                     padding='same',\n","                     use_bias=False,\n","                     kernel_initializer=conv_initializer,\n","                     name=f'encoder_{name}')(input_layer)\n","\n","    if apply_instancenorm:\n","        block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n","\n","    block = activation(block)\n","\n","    return block\n","\n","def transformer_block(input_layer, size=3, strides=1, name='block_x'):\n","    filters = input_layer.shape[-1]\n","\n","    block = L.Conv2D(filters, size, strides=strides, padding='same', use_bias=False,\n","                     kernel_initializer=conv_initializer, name=f'transformer_{name}_1')(input_layer)\n","#     block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n","    block = L.ReLU()(block)\n","\n","    block = L.Conv2D(filters, size, strides=strides, padding='same', use_bias=False,\n","                     kernel_initializer=conv_initializer, name=f'transformer_{name}_2')(block)\n","#     block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n","\n","    block = L.Add()([block, input_layer])\n","\n","    return block\n","\n","def decoder_block(input_layer, filters, size=3, strides=2, apply_instancenorm=True, name='block_x'):\n","    block = L.Conv2DTranspose(filters, size,\n","                              strides=strides,\n","                              padding='same',\n","                              use_bias=False,\n","                              kernel_initializer=conv_initializer,\n","                              name=f'decoder_{name}')(input_layer)\n","\n","    if apply_instancenorm:\n","        block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n","\n","    block = L.ReLU()(block)\n","\n","    return block\n","\n","# Resized convolution\n","def decoder_rc_block(input_layer, filters, size=3, strides=1, apply_instancenorm=True, name='block_x'):\n","    block = tf.image.resize(images=input_layer, method='bilinear',\n","                            size=(input_layer.shape[1]*2, input_layer.shape[2]*2))\n","\n","#     block = tf.pad(block, [[0, 0], [1, 1], [1, 1], [0, 0]], \"SYMMETRIC\") # Works only with GPU\n","#     block = L.Conv2D(filters, size, strides=strides, padding='valid', use_bias=False, # Works only with GPU\n","    block = L.Conv2D(filters, size,\n","                     strides=strides,\n","                     padding='same',\n","                     use_bias=False,\n","                     kernel_initializer=conv_initializer,\n","                     name=f'decoder_{name}')(block)\n","\n","    if apply_instancenorm:\n","        block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n","\n","    block = L.ReLU()(block)\n","\n","    return block"]},{"cell_type":"markdown","id":"identical-cardiff","metadata":{"id":"identical-cardiff"},"source":["# Generator model\n","\n","The `generator` is responsible for generating images from a specific domain. `CycleGAN` architecture has two generators, in this context we will have one `generator` that will take `photos` and generate `Monet paints`, and the other `generator` will take `Monet paintings` and generate `photos`.\n","\n","Bellow, we have the architecture of the original `CycleGAN` `generator`, ours have some changes to improve performance on this task.\n","\n","<center><img src='https://github.com/dimitreOliveira/MachineLearning/blob/master/Kaggle/I%E2%80%99m%20Something%20of%20a%20Painter%20Myself/generator_architecture.png?raw=true' height=250></center>"]},{"cell_type":"code","execution_count":11,"id":"addressed-inspection","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1312,"status":"ok","timestamp":1713704653011,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"addressed-inspection","outputId":"8549bd44-5355-4194-e815-2eea97401f47"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_image (InputLayer)    [(None, None, None, 3)]      0         []                            \n","                                                                                                  \n"," encoder_block_1 (Conv2D)    (None, None, None, 64)       9408      ['input_image[0][0]']         \n","                                                                                                  \n"," re_lu_1 (ReLU)              (None, None, None, 64)       0         ['encoder_block_1[0][0]']     \n","                                                                                                  \n"," encoder_block_2 (Conv2D)    (None, None, None, 128)      73728     ['re_lu_1[0][0]']             \n","                                                                                                  \n"," instance_normalization (In  (None, None, None, 128)      256       ['encoder_block_2[0][0]']     \n"," stanceNormalization)                                                                             \n","                                                                                                  \n"," re_lu_2 (ReLU)              (None, None, None, 128)      0         ['instance_normalization[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," encoder_block_3 (Conv2D)    (None, None, None, 256)      294912    ['re_lu_2[0][0]']             \n","                                                                                                  \n"," instance_normalization_1 (  (None, None, None, 256)      512       ['encoder_block_3[0][0]']     \n"," InstanceNormalization)                                                                           \n","                                                                                                  \n"," re_lu_3 (ReLU)              (None, None, None, 256)      0         ['instance_normalization_1[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," transformer_block_1_1 (Con  (None, None, None, 256)      589824    ['re_lu_3[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," re_lu_4 (ReLU)              (None, None, None, 256)      0         ['transformer_block_1_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," transformer_block_1_2 (Con  (None, None, None, 256)      589824    ['re_lu_4[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," add (Add)                   (None, None, None, 256)      0         ['transformer_block_1_2[0][0]'\n","                                                                    , 're_lu_3[0][0]']            \n","                                                                                                  \n"," transformer_block_2_1 (Con  (None, None, None, 256)      589824    ['add[0][0]']                 \n"," v2D)                                                                                             \n","                                                                                                  \n"," re_lu_5 (ReLU)              (None, None, None, 256)      0         ['transformer_block_2_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," transformer_block_2_2 (Con  (None, None, None, 256)      589824    ['re_lu_5[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," add_1 (Add)                 (None, None, None, 256)      0         ['transformer_block_2_2[0][0]'\n","                                                                    , 'add[0][0]']                \n","                                                                                                  \n"," transformer_block_3_1 (Con  (None, None, None, 256)      589824    ['add_1[0][0]']               \n"," v2D)                                                                                             \n","                                                                                                  \n"," re_lu_6 (ReLU)              (None, None, None, 256)      0         ['transformer_block_3_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," transformer_block_3_2 (Con  (None, None, None, 256)      589824    ['re_lu_6[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," add_2 (Add)                 (None, None, None, 256)      0         ['transformer_block_3_2[0][0]'\n","                                                                    , 'add_1[0][0]']              \n","                                                                                                  \n"," transformer_block_4_1 (Con  (None, None, None, 256)      589824    ['add_2[0][0]']               \n"," v2D)                                                                                             \n","                                                                                                  \n"," re_lu_7 (ReLU)              (None, None, None, 256)      0         ['transformer_block_4_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," transformer_block_4_2 (Con  (None, None, None, 256)      589824    ['re_lu_7[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," add_3 (Add)                 (None, None, None, 256)      0         ['transformer_block_4_2[0][0]'\n","                                                                    , 'add_2[0][0]']              \n","                                                                                                  \n"," transformer_block_5_1 (Con  (None, None, None, 256)      589824    ['add_3[0][0]']               \n"," v2D)                                                                                             \n","                                                                                                  \n"," re_lu_8 (ReLU)              (None, None, None, 256)      0         ['transformer_block_5_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," transformer_block_5_2 (Con  (None, None, None, 256)      589824    ['re_lu_8[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," add_4 (Add)                 (None, None, None, 256)      0         ['transformer_block_5_2[0][0]'\n","                                                                    , 'add_3[0][0]']              \n","                                                                                                  \n"," transformer_block_6_1 (Con  (None, None, None, 256)      589824    ['add_4[0][0]']               \n"," v2D)                                                                                             \n","                                                                                                  \n"," re_lu_9 (ReLU)              (None, None, None, 256)      0         ['transformer_block_6_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," transformer_block_6_2 (Con  (None, None, None, 256)      589824    ['re_lu_9[0][0]']             \n"," v2D)                                                                                             \n","                                                                                                  \n"," add_5 (Add)                 (None, None, None, 256)      0         ['transformer_block_6_2[0][0]'\n","                                                                    , 'add_4[0][0]']              \n","                                                                                                  \n"," enc_dec_skip_1 (Concatenat  (None, None, None, 512)      0         ['add_5[0][0]',               \n"," e)                                                                  're_lu_3[0][0]']             \n","                                                                                                  \n"," decoder_block_1 (Conv2DTra  (None, None, None, 128)      589824    ['enc_dec_skip_1[0][0]']      \n"," nspose)                                                                                          \n","                                                                                                  \n"," instance_normalization_2 (  (None, None, None, 128)      256       ['decoder_block_1[0][0]']     \n"," InstanceNormalization)                                                                           \n","                                                                                                  \n"," re_lu_10 (ReLU)             (None, None, None, 128)      0         ['instance_normalization_2[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," enc_dec_skip_2 (Concatenat  (None, None, None, 256)      0         ['re_lu_10[0][0]',            \n"," e)                                                                  're_lu_2[0][0]']             \n","                                                                                                  \n"," decoder_block_2 (Conv2DTra  (None, None, None, 64)       147456    ['enc_dec_skip_2[0][0]']      \n"," nspose)                                                                                          \n","                                                                                                  \n"," instance_normalization_3 (  (None, None, None, 64)       128       ['decoder_block_2[0][0]']     \n"," InstanceNormalization)                                                                           \n","                                                                                                  \n"," re_lu_11 (ReLU)             (None, None, None, 64)       0         ['instance_normalization_3[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," enc_dec_skip_3 (Concatenat  (None, None, None, 128)      0         ['re_lu_11[0][0]',            \n"," e)                                                                  're_lu_1[0][0]']             \n","                                                                                                  \n"," decoder_output_block (Conv  (None, None, None, 3)        18816     ['enc_dec_skip_3[0][0]']      \n"," 2D)                                                                                              \n","                                                                                                  \n","==================================================================================================\n","Total params: 8213184 (31.33 MB)\n","Trainable params: 8213184 (31.33 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["def generator_fn(height=None, width=None, channels=CHANNELS, transformer_blocks=TRANSFORMER_BLOCKS):\n","    OUTPUT_CHANNELS = 3\n","    inputs = L.Input(shape=[height, width, channels], name='input_image')\n","\n","    # Encoder\n","    enc_1 = encoder_block(inputs, 64,  7, 1, apply_instancenorm=False, activation=L.ReLU(), name='block_1') # (bs, 256, 256, 64)\n","    enc_2 = encoder_block(enc_1, 128, 3, 2, apply_instancenorm=True, activation=L.ReLU(), name='block_2')   # (bs, 128, 128, 128)\n","    enc_3 = encoder_block(enc_2, 256, 3, 2, apply_instancenorm=True, activation=L.ReLU(), name='block_3')   # (bs, 64, 64, 256)\n","\n","    # Transformer\n","    x = enc_3\n","    for n in range(transformer_blocks):\n","        x = transformer_block(x, 3, 1, name=f'block_{n+1}') # (bs, 64, 64, 256)\n","\n","    # Decoder\n","    x_skip = L.Concatenate(name='enc_dec_skip_1')([x, enc_3]) # encoder - decoder skip connection\n","\n","    dec_1 = decoder_block(x_skip, 128, 3, 2, apply_instancenorm=True, name='block_1') # (bs, 128, 128, 128)\n","    x_skip = L.Concatenate(name='enc_dec_skip_2')([dec_1, enc_2]) # encoder - decoder skip connection\n","\n","    dec_2 = decoder_block(x_skip, 64,  3, 2, apply_instancenorm=True, name='block_2') # (bs, 256, 256, 64)\n","    x_skip = L.Concatenate(name='enc_dec_skip_3')([dec_2, enc_1]) # encoder - decoder skip connection\n","\n","    outputs = last = L.Conv2D(OUTPUT_CHANNELS, 7,\n","                              strides=1, padding='same',\n","                              kernel_initializer=conv_initializer,\n","                              use_bias=False,\n","                              activation='tanh',\n","                              name='decoder_output_block')(x_skip) # (bs, 256, 256, 3)\n","\n","    generator = Model(inputs, outputs)\n","\n","    return generator\n","\n","sample_generator = generator_fn()\n","sample_generator.summary()"]},{"cell_type":"markdown","id":"seasonal-watershed","metadata":{"id":"seasonal-watershed"},"source":["# Discriminator model\n","\n","\n","The `discriminator` is responsible for differentiating real images from images that have been generated by a `generator` model.\n","\n","Bellow, we have the architecture of the original `CycleGAN` `discriminator`, again, ours have some changes to improve performance on this task.\n","\n","<center><img src='https://github.com/dimitreOliveira/MachineLearning/blob/master/Kaggle/I%E2%80%99m%20Something%20of%20a%20Painter%20Myself/discriminator_architecture.png?raw=true' height=550, width=550></center>"]},{"cell_type":"code","execution_count":12,"id":"african-shade","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107,"status":"ok","timestamp":1713704653013,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"african-shade","outputId":"490b5bd2-9d5e-4d41-ed94-ea758839b612"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_image (InputLayer)    [(None, 256, 256, 3)]     0         \n","                                                                 \n"," encoder_block_1 (Conv2D)    (None, 128, 128, 64)      3072      \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 128, 128, 64)      0         \n","                                                                 \n"," encoder_block_2 (Conv2D)    (None, 64, 64, 128)       131072    \n","                                                                 \n"," instance_normalization_4 (  (None, 64, 64, 128)       256       \n"," InstanceNormalization)                                          \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 64, 64, 128)       0         \n","                                                                 \n"," encoder_block_3 (Conv2D)    (None, 32, 32, 256)       524288    \n","                                                                 \n"," instance_normalization_5 (  (None, 32, 32, 256)       512       \n"," InstanceNormalization)                                          \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 256)       0         \n","                                                                 \n"," encoder_block_4 (Conv2D)    (None, 32, 32, 512)       2097152   \n","                                                                 \n"," instance_normalization_6 (  (None, 32, 32, 512)       1024      \n"," InstanceNormalization)                                          \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 512)       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 29, 29, 1)         8193      \n","                                                                 \n","=================================================================\n","Total params: 2765569 (10.55 MB)\n","Trainable params: 2765569 (10.55 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["def discriminator_fn(height=HEIGHT, width=WIDTH, channels=CHANNELS):\n","    inputs = L.Input(shape=[height, width, channels], name='input_image')\n","    #inputs_patch = L.experimental.preprocessing.RandomCrop(height=70, width=70, name='input_image_patch')(inputs) # Works only with GPU\n","\n","    # Encoder\n","    x = encoder_block(inputs, 64,  4, 2, apply_instancenorm=False, activation=L.LeakyReLU(0.2), name='block_1') # (bs, 128, 128, 64)\n","    x = encoder_block(x, 128, 4, 2, apply_instancenorm=True, activation=L.LeakyReLU(0.2), name='block_2')       # (bs, 64, 64, 128)\n","    x = encoder_block(x, 256, 4, 2, apply_instancenorm=True, activation=L.LeakyReLU(0.2), name='block_3')       # (bs, 32, 32, 256)\n","    x = encoder_block(x, 512, 4, 1, apply_instancenorm=True, activation=L.LeakyReLU(0.2), name='block_4')       # (bs, 32, 32, 512)\n","\n","    outputs = L.Conv2D(1, 4, strides=1, padding='valid', kernel_initializer=conv_initializer)(x)                # (bs, 29, 29, 1)\n","\n","    discriminator = Model(inputs, outputs)\n","\n","    return discriminator\n","\n","\n","sample_discriminator = discriminator_fn()\n","sample_discriminator.summary()"]},{"cell_type":"markdown","id":"wrapped-wilson","metadata":{"id":"wrapped-wilson"},"source":["# Build model (CycleGAN)"]},{"cell_type":"code","execution_count":13,"id":"changing-device","metadata":{"id":"changing-device","executionInfo":{"status":"ok","timestamp":1713704653506,"user_tz":240,"elapsed":537,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["anime_generator = generator_fn(height=None, width=None, transformer_blocks=TRANSFORMER_BLOCKS) # transforms photos to anime-esque paintings\n","photo_generator = generator_fn(height=None, width=None, transformer_blocks=TRANSFORMER_BLOCKS) # transforms anime paintings to be more like photos\n","\n","anime_discriminator = discriminator_fn(height=None, width=None) # differentiates real anime paintings and generated anime paintings\n","photo_discriminator = discriminator_fn(height=None, width=None) # differentiates real photos and generated photos\n","\n","\n","class CycleGan(Model):\n","    def __init__(\n","        self,\n","        anime_generator,\n","        photo_generator,\n","        anime_discriminator,\n","        photo_discriminator,\n","        lambda_cycle=10,\n","    ):\n","        super(CycleGan, self).__init__()\n","        self.m_gen = anime_generator\n","        self.p_gen = photo_generator\n","        self.m_disc = anime_discriminator\n","        self.p_disc = photo_discriminator\n","        self.lambda_cycle = lambda_cycle\n","\n","    def compile(\n","        self,\n","        m_gen_optimizer,\n","        p_gen_optimizer,\n","        m_disc_optimizer,\n","        p_disc_optimizer,\n","        gen_loss_fn,\n","        disc_loss_fn,\n","        cycle_loss_fn,\n","        identity_loss_fn\n","    ):\n","        super(CycleGan, self).compile()\n","        self.m_gen_optimizer = m_gen_optimizer\n","        self.p_gen_optimizer = p_gen_optimizer\n","        self.m_disc_optimizer = m_disc_optimizer\n","        self.p_disc_optimizer = p_disc_optimizer\n","        self.gen_loss_fn = gen_loss_fn\n","        self.disc_loss_fn = disc_loss_fn\n","        self.cycle_loss_fn = cycle_loss_fn\n","        self.identity_loss_fn = identity_loss_fn\n","\n","    def train_step(self, batch_data):\n","        real_anime, real_photo = batch_data\n","\n","        with tf.GradientTape(persistent=True) as tape:\n","            # photo to anime back to photo\n","            fake_anime = self.m_gen(real_photo, training=True)\n","            cycled_photo = self.p_gen(fake_anime, training=True)\n","\n","            # anime to photo back to anime\n","            fake_photo = self.p_gen(real_anime, training=True)\n","            cycled_anime = self.m_gen(fake_photo, training=True)\n","\n","            # generating itself\n","            same_anime = self.m_gen(real_anime, training=True)\n","            same_photo = self.p_gen(real_photo, training=True)\n","\n","            # discriminator used to check, inputing real images\n","            disc_real_anime = self.m_disc(real_anime, training=True)\n","            disc_real_photo = self.p_disc(real_photo, training=True)\n","\n","            # discriminator used to check, inputing fake images\n","            disc_fake_anime = self.m_disc(fake_anime, training=True)\n","            disc_fake_photo = self.p_disc(fake_photo, training=True)\n","\n","            # evaluates generator loss\n","            anime_gen_loss = self.gen_loss_fn(disc_fake_anime)\n","            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n","\n","            # evaluates total cycle consistency loss\n","            total_cycle_loss = self.cycle_loss_fn(real_anime, cycled_anime, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n","\n","            # evaluates total generator loss\n","            total_anime_gen_loss = anime_gen_loss + total_cycle_loss + self.identity_loss_fn(real_anime, same_anime, self.lambda_cycle)\n","            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n","\n","            # evaluates discriminator loss\n","            anime_disc_loss = self.disc_loss_fn(disc_real_anime, disc_fake_anime)\n","            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n","\n","        # Calculate the gradients for generator and discriminator\n","        anime_generator_gradients = tape.gradient(total_anime_gen_loss,\n","                                                  self.m_gen.trainable_variables)\n","        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n","                                                  self.p_gen.trainable_variables)\n","\n","        anime_discriminator_gradients = tape.gradient(anime_disc_loss,\n","                                                      self.m_disc.trainable_variables)\n","        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n","                                                      self.p_disc.trainable_variables)\n","\n","        # Apply the gradients to the optimizer\n","        self.m_gen_optimizer.apply_gradients(zip(anime_generator_gradients,\n","                                                 self.m_gen.trainable_variables))\n","\n","        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n","                                                 self.p_gen.trainable_variables))\n","\n","        self.m_disc_optimizer.apply_gradients(zip(anime_discriminator_gradients,\n","                                                  self.m_disc.trainable_variables))\n","\n","        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n","                                                  self.p_disc.trainable_variables))\n","\n","        return {'anime_gen_loss': total_anime_gen_loss,\n","                'photo_gen_loss': total_photo_gen_loss,\n","                'anime_disc_loss': anime_disc_loss,\n","                'photo_disc_loss': photo_disc_loss\n","               }"]},{"cell_type":"markdown","id":"regular-conviction","metadata":{"id":"regular-conviction"},"source":["# Loss functions"]},{"cell_type":"code","execution_count":14,"id":"broadband-topic","metadata":{"id":"broadband-topic","executionInfo":{"status":"ok","timestamp":1713704653508,"user_tz":240,"elapsed":49,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["# Discriminator loss {0: fake, 1: real} (The discriminator loss outputs the average of the real and generated loss)\n","def discriminator_loss(real, generated):\n","    real_loss = losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.ones_like(real), real)\n","\n","    generated_loss = losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n","\n","    total_disc_loss = real_loss + generated_loss\n","\n","    return total_disc_loss * 0.5\n","\n","# Generator loss\n","def generator_loss(generated):\n","    return losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.ones_like(generated), generated)\n","\n","\n","# Cycle consistency loss (measures if original photo and the twice transformed photo to be similar to one another)\n","\n","def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n","    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n","\n","    return LAMBDA * loss1\n","\n","# Identity loss (compares the image with its generator (i.e. photo with photo generator))\n","\n","def identity_loss(real_image, same_image, LAMBDA):\n","    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n","    return LAMBDA * 0.5 * loss"]},{"cell_type":"markdown","id":"completed-prescription","metadata":{"id":"completed-prescription"},"source":["## Learning rate schedule\n","\n","The original `CycleGAN` implementation used a `constant learning rate schedule with a linear decay`, I also found that the linear decay phase seems to be good at making the model more stable at the last epochs, you can check how the `generator` changes in a more conservative rate by the end looking at the `gif` images by the end."]},{"cell_type":"code","execution_count":15,"id":"superior-witch","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526},"executionInfo":{"elapsed":12631,"status":"ok","timestamp":1713704666112,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"},"user_tz":240},"id":"superior-witch","outputId":"9b74a4bd-8515-4ed7-cd82-b3d5967390cb"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function linear_schedule_with_warmup at 0x7a95ec0b65f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function linear_schedule_with_warmup at 0x7a95ec0b65f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["30 total epochs and 416 steps per epoch\n","Learning rate schedule: 0.0002 to 0.0002 to 2.4e-06\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["@tf.function\n","def linear_schedule_with_warmup(step):\n","    lr_start = 2e-4\n","    lr_max = 2e-4\n","    lr_min = 0.0\n","\n","    steps_per_epoch = int(max(n_anime_samples, n_photo_samples) // BATCH_SIZE)\n","    total_steps = EPOCHS * steps_per_epoch\n","    warmup_steps = 1\n","    hold_max_steps = int(total_steps * 0.8)\n","\n","    # Convert step and warmup_steps to float for safe division\n","    step = tf.cast(step, tf.float32)\n","    warmup_steps = tf.cast(warmup_steps, tf.float32)\n","    total_steps = tf.cast(total_steps, tf.float32)\n","    hold_max_steps = tf.cast(hold_max_steps, tf.float32)\n","\n","    if step < warmup_steps:\n","        lr = (lr_max - lr_start) / warmup_steps * step + lr_start\n","    elif step < warmup_steps + hold_max_steps:\n","        lr = lr_max\n","    else:\n","        remaining_steps = total_steps - step\n","        decay_steps = total_steps - warmup_steps - hold_max_steps\n","        lr = lr_max * (remaining_steps / decay_steps)\n","        if lr_min is not None:\n","            lr = tf.maximum(lr_min, lr)\n","\n","    return lr\n","\n","steps_per_epoch = int(max(n_anime_samples, n_photo_samples)//BATCH_SIZE)\n","total_steps = EPOCHS * steps_per_epoch\n","rng = [i for i in range(0, total_steps, 50)]\n","y = [linear_schedule_with_warmup(x) for x in rng]\n","\n","sns.set(style=\"whitegrid\")\n","fig, ax = plt.subplots(figsize=(20, 6))\n","plt.plot(rng, y)\n","print(f'{EPOCHS} total epochs and {steps_per_epoch} steps per epoch')\n","print(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')"]},{"cell_type":"markdown","id":"suffering-nigeria","metadata":{"id":"suffering-nigeria"},"source":["# Train"]},{"cell_type":"code","execution_count":16,"id":"green-integral","metadata":{"id":"green-integral","executionInfo":{"status":"ok","timestamp":1713704666115,"user_tz":240,"elapsed":90,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["# Create generators\n","lr_anime_gen = lambda: linear_schedule_with_warmup(tf.cast(anime_generator_optimizer.iterations, tf.float32))\n","lr_photo_gen = lambda: linear_schedule_with_warmup(tf.cast(photo_generator_optimizer.iterations, tf.float32))\n","\n","current_step = tf.Variable(0, dtype=tf.int64)\n","\n","def lr_anime_gen():\n","    return linear_schedule_with_warmup(current_step.value())\n","\n","def lr_photo_gen():\n","    return linear_schedule_with_warmup(current_step.value())\n","\n","anime_generator_optimizer = optimizers.Adam(learning_rate=lr_anime_gen(), beta_1=0.5)\n","photo_generator_optimizer = optimizers.Adam(learning_rate=lr_photo_gen(), beta_1=0.5)\n","\n","\n","# Create discriminators\n","lr_anime_disc = lambda: linear_schedule_with_warmup(tf.cast(anime_discriminator_optimizer.iterations, tf.float32))\n","lr_photo_disc = lambda: linear_schedule_with_warmup(tf.cast(photo_discriminator_optimizer.iterations, tf.float32))\n","\n","anime_discriminator_step = tf.Variable(0, dtype=tf.int64)\n","photo_discriminator_step = tf.Variable(0, dtype=tf.int64)\n","\n","def lr_anime_disc():\n","    return linear_schedule_with_warmup(anime_discriminator_step)\n","\n","def lr_photo_disc():\n","    return linear_schedule_with_warmup(photo_discriminator_step)\n","\n","# Create optimizers using lambda functions for dynamic learning rate adjustments\n","anime_discriminator_optimizer = optimizers.Adam(learning_rate=lr_anime_disc(), beta_1=0.5)\n","photo_discriminator_optimizer = optimizers.Adam(learning_rate=lr_photo_disc(), beta_1=0.5)\n","\n","# Create GAN\n","gan_model = CycleGan(anime_generator, photo_generator,\n","                        anime_discriminator, photo_discriminator)\n","\n","gan_model.compile(m_gen_optimizer=anime_generator_optimizer,\n","                    p_gen_optimizer=photo_generator_optimizer,\n","                    m_disc_optimizer=anime_discriminator_optimizer,\n","                    p_disc_optimizer=photo_discriminator_optimizer,\n","                    gen_loss_fn=generator_loss,\n","                    disc_loss_fn=discriminator_loss,\n","                    cycle_loss_fn=calc_cycle_loss,\n","                    identity_loss_fn=identity_loss)"]},{"cell_type":"code","execution_count":17,"id":"opened-liabilities","metadata":{"id":"opened-liabilities","executionInfo":{"status":"ok","timestamp":1713704668552,"user_tz":240,"elapsed":2500,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}}},"outputs":[],"source":["# Create dataset\n","anime_ds = get_dataset(ANIME_FILENAMES, augment=data_augment, batch_size=BATCH_SIZE)\n","photo_ds = get_dataset(PHOTO_FILENAMES, augment=data_augment, batch_size=BATCH_SIZE)\n","gan_ds = tf.data.Dataset.zip((anime_ds, photo_ds))\n","\n","photo_ds_eval = get_dataset(TEST_FILENAMES, repeat=False, shuffle=False, batch_size=1)\n","anime_ds_eval = get_dataset(ANIME_FILENAMES, repeat=False, shuffle=False, batch_size=1)\n","\n","# Callbacks\n","class GANMonitor(Callback):\n","    \"\"\"A callback to generate and save images after each epoch\"\"\"\n","\n","    def __init__(self, num_img=10, anime_path='anime', photo_path='photo'):\n","        self.num_img = num_img\n","        self.anime_path = anime_path\n","        self.photo_path = photo_path\n","        # Create directories to save the generate images\n","        if not os.path.exists(self.anime_path):\n","            os.makedirs(self.anime_path)\n","        if not os.path.exists(self.photo_path):\n","            os.makedirs(self.photo_path)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # anime generated images\n","        for i, img in enumerate(photo_ds_eval.take(self.num_img)):\n","            print(img.shape)\n","            prediction = anime_generator(img, training=False)[0].numpy()\n","            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n","            prediction = PIL.Image.fromarray(prediction)\n","            prediction.save(f'{self.anime_path}/generated_{i}_{epoch+1}.png')\n","\n","        # Photo generated images\n","        for i, img in enumerate(photo_ds_eval.take(self.num_img)):\n","            prediction = photo_generator(img, training=False)[0].numpy()\n","            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n","            prediction = PIL.Image.fromarray(prediction)\n","            prediction.save(f'{self.photo_path}/generated_{i}_{epoch+1}.png')"]},{"cell_type":"code","source":["for i, img in enumerate(photo_ds_eval.take(1)):\n","    print(img.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZpVgCnMNj06","executionInfo":{"status":"ok","timestamp":1713704669463,"user_tz":240,"elapsed":950,"user":{"displayName":"Yufei Wang","userId":"11015260917326285891"}},"outputId":"59161159-8df9-4abc-9ac7-8c1adadc3ae9"},"id":"UZpVgCnMNj06","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 256, 256, 3)\n"]}]},{"cell_type":"code","execution_count":null,"id":"suspected-likelihood","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suspected-likelihood","outputId":"8c87ed8e-d492-47c0-aa64-f23016627e76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","416/416 - 374s - anime_gen_loss: 2.8314 - photo_gen_loss: 3.6805 - anime_disc_loss: 0.6655 - photo_disc_loss: 0.2989 - 374s/epoch - 899ms/step\n","Epoch 2/30\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","416/416 - 347s - anime_gen_loss: 2.7474 - photo_gen_loss: 3.1215 - anime_disc_loss: 0.6464 - photo_disc_loss: 0.4758 - 347s/epoch - 834ms/step\n","Epoch 3/30\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","416/416 - 343s - anime_gen_loss: 2.6200 - photo_gen_loss: 3.1481 - anime_disc_loss: 0.6490 - photo_disc_loss: 0.5441 - 343s/epoch - 824ms/step\n","Epoch 4/30\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","(1, 256, 256, 3)\n","416/416 - 345s - anime_gen_loss: 2.5055 - photo_gen_loss: 3.0660 - anime_disc_loss: 0.7000 - photo_disc_loss: 0.5273 - 345s/epoch - 829ms/step\n","Epoch 5/30\n"]}],"source":["history = gan_model.fit(gan_ds,\n","                        epochs=EPOCHS,\n","                        callbacks=[GANMonitor()],\n","                        steps_per_epoch=(max(n_anime_samples, n_photo_samples)//BATCH_SIZE),\n","                        verbose=2).history"]},{"cell_type":"code","execution_count":null,"id":"qeA5XIy18P4D","metadata":{"id":"qeA5XIy18P4D"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"transsexual-surfing","metadata":{"id":"transsexual-surfing"},"source":["We can see the generators progress at each epoch by creating a `gif` that is a generated image at each epoch.\n","\n","## anime generation GIF"]},{"cell_type":"markdown","id":"sexual-mailing","metadata":{"id":"sexual-mailing"},"source":["<img src='anime.gif' width=350>"]},{"cell_type":"markdown","id":"industrial-belief","metadata":{"id":"industrial-belief"},"source":["## Photo generation GIF"]},{"cell_type":"markdown","id":"historical-ethnic","metadata":{"id":"historical-ethnic"},"source":["<img src='photo.gif' width=350>"]},{"cell_type":"markdown","id":"pregnant-indiana","metadata":{"id":"pregnant-indiana"},"source":["# Evaluating generator models\n","\n","Here we are going to evaluate the generator models including how good is the generator cycle, this means that we will get a photo to generate a anime picture from it, then use the generated picture to generate the original photo.\n","\n","## Photo (input) -> anime (generated) -> Photo (generated)"]},{"cell_type":"markdown","id":"departmental-pavilion","metadata":{"id":"departmental-pavilion"},"source":["Here we will do the same process but starting with a anime picture.\n","\n","## anime (input) -> Photo (generated) -> anime (generated)"]},{"cell_type":"markdown","id":"exceptional-banks","metadata":{"id":"exceptional-banks"},"source":["# Visualize predictions\n","\n","A common issue with images generated by GANs is that the often show some undisered artifacts, a very common on is known as \"[checkerboard artifacts](https://distill.pub/2016/deconv-checkerboard/)\", a good practice is to inspect some of the images to see its quality and if some of these undisered artifacts are present."]},{"cell_type":"markdown","id":"exotic-december","metadata":{"id":"exotic-december"},"source":["## Make predictions"]},{"cell_type":"markdown","id":"republican-yeast","metadata":{"id":"republican-yeast"},"source":["# Submission file"]},{"cell_type":"markdown","id":"initial-nomination","metadata":{"id":"initial-nomination"},"source":["## Output models"]},{"cell_type":"code","execution_count":null,"id":"infrared-george","metadata":{"id":"infrared-george"},"outputs":[],"source":["anime_generator.save('anime_generator.h5')\n","photo_generator.save('photo_generator.h5')\n","anime_discriminator.save('anime_discriminator.h5')\n","photo_discriminator.save('photo_discriminator.h5')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"RkXs048qLTY6"},"id":"RkXs048qLTY6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/gdrive/MyDrive/CycleGAN\")\n","!apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic\n","!jupyter nbconvert --to pdf 'CycleGAN_style_transfer.ipynb' --output '/content/gdrive/MyDrive/CycleGAN/CycleGAN_style_transfer.pdf'"],"metadata":{"id":"Nh_nUhXvKj1g"},"id":"Nh_nUhXvKj1g","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"papermill":{"default_parameters":{},"duration":6218.949008,"end_time":"2021-04-17T22:25:39.191933","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-04-17T20:42:00.242925","version":"2.3.2"}},"nbformat":4,"nbformat_minor":5}